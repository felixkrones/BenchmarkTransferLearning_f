{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6527b5ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a392140b",
   "metadata": {},
   "source": [
    "## 0. Initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f71de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from main_classification import get_args_parser\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from trainer import test_classification\n",
    "from evaluation.plex_metrics import plex_evaluate\n",
    "from dataloader import *\n",
    "from utils import metric_AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816ad746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "args = get_args_parser(main_args=False).get_default_values()\n",
    "args.device = \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21b8b9c1",
   "metadata": {},
   "source": [
    "## 1. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09db31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "args.data_dir = \"/Users/felixkrones/python_projects/data/NIH/images/\"  # /Users/felixkrones/python_projects/data/NIH/images/ /Users/felixkrones/python_projects/data/ChestXpert/ /Users/felixkrones/python_projects/data/Padchest/0_224_224/ /Users/felixkrones/python_projects/data/VinDrCXR/\n",
    "args.test_list = \"dataset/Xray14_test_official.txt\"  # dataset/Xray14_test_official.txt dataset/CheXpert_valid_official_frontal.csv dataset/CheXpert_test_Glocker.csv dataset/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv dataset/VinDrCXR_test_pe_global_one.txt\n",
    "args.metadata_file = \"\"\n",
    "if \"CheXpert_valid_official_frontal.csv\" in args.test_list:\n",
    "    args.metadata_file = \"dataset/chestxpert_valid_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00677430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models\n",
    "args.nc = 3\n",
    "model_list = [\n",
    "    (\"ResNet50\", \"/Users/felixkrones/python_projects/models/BenchmarkTransferLearning_f/Classification/ChestXray14/ResNet50_random/ResNet50_random_run_0_best.pth.tar\"),\n",
    "    (\"ResNet50\", \"/Users/felixkrones/python_projects/models/BenchmarkTransferLearning_f/Classification/ChestXray14/ResNet50_random/ResNet50_random_run_1_best.pth.tar\"),\n",
    "    (\"ResNet50\", \"/Users/felixkrones/python_projects/models/BenchmarkTransferLearning_f/Classification/ChestXray14/ResNet50_random/ResNet50_random_run_2_best.pth.tar\"),\n",
    "    (\"ResNet50\", \"/Users/felixkrones/python_projects/models/BenchmarkTransferLearning_f/Classification/ChestXray14/ResNet50_imagenet/ResNet50_imagenet_run_0_best.pth.tar\"),\n",
    "    (\"ResNet50\", \"/Users/felixkrones/python_projects/models/BenchmarkTransferLearning_f/Classification/ChestXray14/ResNet50_imagenet/ResNet50_imagenet_run_1_best.pth.tar\"),\n",
    "    (\"ResNet50\", \"/Users/felixkrones/python_projects/models/BenchmarkTransferLearning_f/Classification/ChestXray14/ResNet50_imagenet/ResNet50_imagenet_run_2_best.pth.tar\"),\n",
    "]\n",
    "diseases_model = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Effusion\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Hernia\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14ba81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNMML models nc 1\n",
    "args.nc = 1\n",
    "model_list = [\n",
    "#    (\"\", \"2.1\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.1_random_scratch_1D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.1_random_scratch_1D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.1_random_scratch_1D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.1_random_scratch_1D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.1_random_scratch_1D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"2.3\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_scratch_MIMIC_1D_1000e_100k/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_scratch_MIMIC_1D_1000e_100k/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_scratch_MIMIC_1D_1000e_100k/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_scratch_MIMIC_1D_1000e_100k/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_scratch_MIMIC_1D_1000e_100k/seed_100/best_checkpoint.pth\"),\n",
    "    (\"\", \"0.2.1\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.1_scratch_NIH_1D_v1/seed_0/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.1_scratch_NIH_1D_v1/seed_11/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.1_scratch_NIH_1D_v1/seed_21/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.1_scratch_NIH_1D_v1/seed_42/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.1_scratch_NIH_1D_v1/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"3.1\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.1_scratch_MIMIC_1D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.1_scratch_MIMIC_1D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.1_scratch_MIMIC_1D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.1_scratch_MIMIC_1D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.1_scratch_MIMIC_1D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"3.3\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.3_scratch_OCT_1D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.3_scratch_OCT_1D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.3_scratch_OCT_1D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.3_scratch_OCT_1D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.3_scratch_OCT_1D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"3.5\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.5_scratch_CovidxCT_1D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.5_scratch_CovidxCT_1D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.5_scratch_CovidxCT_1D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.5_scratch_CovidxCT_1D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.5_scratch_CovidxCT_1D/seed_100/best_checkpoint.pth\"),\n",
    "]\n",
    "diseases_model = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Effusion\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Hernia\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c75d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNMML models nc 3\n",
    "args.nc = 3\n",
    "model_list = [\n",
    "#    (\"\", \"2.2\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.2_imagenet_scratch_3D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.2_imagenet_scratch_3D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.2_imagenet_scratch_3D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.2_imagenet_scratch_3D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/2.2_imagenet_scratch_3D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"2.4\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_imagenet_MIMIC_3D_1000e_100k/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_imagenet_MIMIC_3D_1000e_100k/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_imagenet_MIMIC_3D_1000e_100k/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_imagenet_MIMIC_3D_1000e_100k/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/supervised_imagenet_MIMIC_3D_1000e_100k/seed_100/best_checkpoint.pth\"),\n",
    "    (\"\", \"0.2.4\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_0/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_11/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_21/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_42/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_100/best_checkpoint.pth\"),\n",
    "    (\"\", \"0.2.5\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_0/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_11/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_21/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_42/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_100/best_checkpoint.pth\"),\n",
    "    (\"\", \"0.2.6\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_0/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_11/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_21/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_42/best_checkpoint.pth\"),\n",
    "    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"3.2\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.2_timm_MIMIC_3D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.2_timm_MIMIC_3D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.2_timm_MIMIC_3D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.2_timm_MIMIC_3D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.2_timm_MIMIC_3D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"3.4\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.4_timm_OCT_3D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.4_timm_OCT_3D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.4_timm_OCT_3D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.4_timm_OCT_3D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.4_timm_OCT_3D/seed_100/best_checkpoint.pth\"),\n",
    "#    (\"\", \"3.6\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.6_timm_CovidxCT_3D/seed_0/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.6_timm_CovidxCT_3D/seed_11/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.6_timm_CovidxCT_3D/seed_21/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.6_timm_CovidxCT_3D/seed_42/best_checkpoint.pth\"),\n",
    "#    (\"vit_small\", \"/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/3.6_timm_CovidxCT_3D/seed_100/best_checkpoint.pth\"),\n",
    "]\n",
    "diseases_model = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Effusion\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Hernia\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cd2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define eval params\n",
    "eval_params = {\n",
    "    \"selective_threshold\": [0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"independent_reg_variable\": \"StudyDate\",\n",
    "    \"subpopulation_groups\": [\"sex_label\", \"race_label\"],\n",
    "    \"ece_num_bins\": 15,\n",
    "}\n",
    "decision_thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "diseases_to_test = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Effusion\"]\n",
    "diseases_to_test = diseases_model\n",
    "index_to_test_model = [diseases_model.index(disease) for disease in diseases_to_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a86c2f17",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3358d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 25596\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "index_to_test_model: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "if \"nih\" in args.data_dir.lower():\n",
    "    dataset_test = ChestXray14Dataset(\n",
    "        images_path=args.data_dir,\n",
    "        file_path=args.test_list,\n",
    "        augment=build_transform_classification(\n",
    "            normalize=args.normalization, mode=\"test\", test_augment=args.test_augment, nc=args.nc\n",
    "        ),\n",
    "        nc=args.nc,\n",
    "    )\n",
    "    diseases = [\n",
    "        \"Atelectasis\",\n",
    "        \"Cardiomegaly\",\n",
    "        \"Effusion\",\n",
    "        \"Infiltration\",\n",
    "        \"Mass\",\n",
    "        \"Nodule\",\n",
    "        \"Pneumonia\",\n",
    "        \"Pneumothorax\",\n",
    "        \"Consolidation\",\n",
    "        \"Edema\",\n",
    "        \"Emphysema\",\n",
    "        \"Fibrosis\",\n",
    "        \"Pleural_Thickening\",\n",
    "        \"Hernia\",\n",
    "    ]\n",
    "    index_to_test_dataset = [diseases.index(disease) for disease in diseases_to_test]\n",
    "elif \"chestxpert\" in args.data_dir.lower():\n",
    "    diseases_to_test = [\n",
    "        disease.replace(\"Effusion\", \"Pleural Effusion\") for disease in diseases_to_test\n",
    "    ]\n",
    "    dataset_test = CheXpertDataset(\n",
    "        images_path=args.data_dir,\n",
    "        file_path=args.test_list,\n",
    "        augment=build_transform_classification(\n",
    "            normalize=args.normalization, mode=\"test\", test_augment=args.test_augment, nc=args.nc\n",
    "        ),\n",
    "        uncertain_label=args.uncertain_label,\n",
    "        unknown_label=args.unknown_label,\n",
    "        nc=args.nc,\n",
    "    )\n",
    "    diseases = [\n",
    "        \"No Finding\",\n",
    "        \"Enlarged Cardiomediastinum\",\n",
    "        \"Cardiomegaly\",\n",
    "        \"Lung Opacity\",\n",
    "        \"Lung Lesion\",\n",
    "        \"Edema\",\n",
    "        \"Consolidation\",\n",
    "        \"Pneumonia\",\n",
    "        \"Atelectasis\",\n",
    "        \"Pneumothorax\",\n",
    "        \"Pleural Effusion\",\n",
    "        \"Pleural Other\",\n",
    "        \"Fracture\",\n",
    "        \"Support Devices\",\n",
    "    ]\n",
    "    index_to_test_dataset = [diseases.index(disease) for disease in diseases_to_test]\n",
    "elif \"padchest\" in args.data_dir.lower():\n",
    "    diseases_to_test = [\n",
    "        disease.replace(\"Effusion\", \"Pleural Effusion\") for disease in diseases_to_test\n",
    "    ]\n",
    "    dataset_test = PadchestDataset(\n",
    "        images_path=args.data_dir,\n",
    "        file_path=args.test_list,\n",
    "        augment=build_transform_classification(\n",
    "            normalize=args.normalization, mode=\"test\", test_augment=args.test_augment, nc=args.nc\n",
    "        ),\n",
    "        diseases_to_test=diseases_to_test,\n",
    "        nc=args.nc,\n",
    "    )\n",
    "    diseases = dataset_test.possible_labels\n",
    "    index_to_test_dataset = [\n",
    "        diseases.index(disease.lower()) for disease in diseases_to_test\n",
    "    ]\n",
    "elif \"vindr\" in args.data_dir.lower():\n",
    "    dataset_test = VinDrCXR(\n",
    "        images_path=args.data_dir,\n",
    "        file_path=args.test_list,\n",
    "        augment=build_transform_classification(\n",
    "            normalize=args.normalization, mode=\"test\", test_augment=args.test_augment, nc=args.nc\n",
    "        ),\n",
    "        nc=args.nc,\n",
    "    )\n",
    "    diseases = dataset_test.possible_labels\n",
    "    index_to_test_dataset = [\n",
    "        diseases.index(disease.replace(\"Effusion\", \"Pleural effusion\"))\n",
    "        for disease in diseases_to_test\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(f\"Dataset {args.data_dir} not supported\")\n",
    "print(f\"Dataset size: {len(dataset_test)}\")\n",
    "print(f\"index_to_test_dataset: {index_to_test_dataset}\")\n",
    "print(f\"index_to_test_model: {index_to_test_model}\")\n",
    "if not len(diseases_to_test) == len(index_to_test_dataset):\n",
    "    print(f\"len(index_to_test_dataset): {len(index_to_test_dataset)}\")\n",
    "    print(f\"len(diseases_to_test): {len(diseases_to_test)}\")\n",
    "    raise ValueError(\"Number of classes does not match the number of diseases to test\")\n",
    "\n",
    "# Get dataloader and model\n",
    "device = torch.device(args.device)\n",
    "cudnn.benchmark = True\n",
    "data_loader_test = DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    sampler=torch.utils.data.SequentialSampler(dataset_test),\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e031431a",
   "metadata": {},
   "source": [
    "## 3. Loop through models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18690bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Starting with experiment 0.2.4 --------------\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_0/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_0/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:40<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7703688416661402, 0.8992600239754108, 0.7593741004202372, 0.8459370505035455, 0.8274840067391506, 0.8863832197256201, 0.8219885546277376, 0.8427132998459338, 0.7067871159353736, 0.82488615445495, 0.7347167802430437, 0.7937632351225389, 0.7270363450787556, 0.8600412707246463]\n",
      "Mean AUC: 0.8072\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_11/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_11/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [11:12<00:00,  1.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7701098137577724, 0.8957463993309067, 0.7583570721029578, 0.8435406270848693, 0.8324221686460191, 0.8738176616273325, 0.8227718778423275, 0.8356071034614789, 0.7053020741075239, 0.8181584651879908, 0.7282259727447025, 0.7790895770589099, 0.7186727640543382, 0.8566241509420995]\n",
      "Mean AUC: 0.8027\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_21/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_21/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:38<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7718750435158004, 0.8999686224261055, 0.7597705902911358, 0.8454848509082226, 0.8302197872957109, 0.8862267514043782, 0.8136460961522737, 0.8297065446291012, 0.7055054309899599, 0.8233230031619019, 0.7291555330821317, 0.783999830553222, 0.7130752053119371, 0.8559973500728959]\n",
      "Mean AUC: 0.8034\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_42/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_42/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:34<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.772944450928683, 0.8985539236784663, 0.7629778987623869, 0.8457266491898245, 0.8342068340883824, 0.8813823196733869, 0.8129618132788063, 0.823703882654317, 0.704800840580968, 0.8260677775607068, 0.7324766471337557, 0.7854162818246255, 0.7211862995138424, 0.8528474402733447]\n",
      "Mean AUC: 0.8039\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_100/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.4_scratch_NIH_3D/seed_100/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:36<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7728407646055631, 0.897510172157882, 0.7622360976880056, 0.8473905789377395, 0.8351914058480371, 0.8865126360724581, 0.8329707488372582, 0.8754072730256259, 0.7061501278132896, 0.820911599646733, 0.7282052701566938, 0.7845562750245717, 0.711208500941339, 0.8557794191776734]\n",
      "Mean AUC: 0.8083\n",
      "-------------- Starting with experiment 0.2.5 --------------\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_0/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_0/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:39<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7731294942896543, 0.8958618102201796, 0.7575871563554626, 0.8503422882977827, 0.8354773253352913, 0.8915220307060258, 0.8088371119873075, 0.8674806049611188, 0.7022846675913974, 0.8262851391190738, 0.7331667334007073, 0.7892290668917276, 0.7250487938519566, 0.8498781522804812]\n",
      "Mean AUC: 0.8076\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_11/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_11/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:37<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7742986797174642, 0.8969081171041416, 0.7664941674506223, 0.8549446937919233, 0.8353187984595876, 0.8946937020128498, 0.8126770266152643, 0.8929740275131504, 0.6952185890409743, 0.8267351790170699, 0.7364099203923165, 0.7890009434421648, 0.7212344008079002, 0.8610400988429027]\n",
      "Mean AUC: 0.8113\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_21/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_21/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:39<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7734191258910208, 0.8947596858093005, 0.7648079936954554, 0.8492616235058779, 0.836583296629797, 0.8863422030328905, 0.8151343965551503, 0.8687249870091983, 0.7074932094571356, 0.8227380868306291, 0.7393823802445239, 0.7895500175511225, 0.724188726884306, 0.8581460917543396]\n",
      "Mean AUC: 0.8093\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_42/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_42/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:38<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7756238558376521, 0.9007752400392031, 0.7594788904214688, 0.8523937832688998, 0.8364008230806436, 0.8983893302980358, 0.8133642331888385, 0.9071467641508573, 0.69802840644653, 0.8321158311372484, 0.7314227941636642, 0.792059983730104, 0.7259814264965817, 0.8525448030198761]\n",
      "Mean AUC: 0.8126\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_100/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.5_sit_imagenet_3D/seed_100/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [14:43<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7722252060652078, 0.9049816732771121, 0.760777656260299, 0.8463291949076879, 0.8349928806965348, 0.892168776390844, 0.8160335257036637, 0.8537652812850409, 0.7024614428901793, 0.8241538036089744, 0.7360807094055982, 0.7848847212709625, 0.7193995720891613, 0.8567315782079905]\n",
      "Mean AUC: 0.8075\n",
      "-------------- Starting with experiment 0.2.6 --------------\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_0/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_0/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [13:23:12<00:00, 120.48s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7729182406660479, 0.8972912881216832, 0.7577640922916564, 0.8470833794355338, 0.8350892620840011, 0.8944055210073985, 0.8225155972548284, 0.8694779976844467, 0.7021057551853529, 0.8140901385740507, 0.7163872151405493, 0.7816140871811544, 0.7201501249662265, 0.859232669867012]\n",
      "Mean AUC: 0.8064\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_11/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_11/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:37<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7722280963001126, 0.8976817629017151, 0.7603328490010371, 0.8496133659499555, 0.8319981366811934, 0.8970952228378853, 0.8361790528764869, 0.8725413198654428, 0.7076669281467086, 0.8181303264496655, 0.7289908376333932, 0.7881155160475508, 0.73187147852297, 0.8664293394090419]\n",
      "Mean AUC: 0.8113\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_21/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_21/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:34<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7699973132430988, 0.8997749869056698, 0.7602557334761425, 0.8509581771792463, 0.8335258431925681, 0.9043490725541421, 0.8354039068856336, 0.9090333931973782, 0.7014993331553558, 0.8169653514977006, 0.7261838185744955, 0.7887463976012118, 0.7243325990420755, 0.8559284918954596]\n",
      "Mean AUC: 0.8126\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_42/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_42/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:27<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7717195721091267, 0.8968249152353549, 0.7580126181247779, 0.8504730250091199, 0.8325980492981363, 0.9028852414919859, 0.8296999507082435, 0.8992415195135515, 0.7035885339467691, 0.8234954338959867, 0.7248238217470933, 0.7879142622201054, 0.7263887944491755, 0.8591263553283228]\n",
      "Mean AUC: 0.8119\n",
      "-------------- Model vit_small from path: /Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_100/best_checkpoint.pth --------------\n",
      "Loading  weights for vit_small from timm.\n",
      "Creating empty model:\n",
      "state_dict to load: odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])\n",
      "Loaded with msg: <All keys matched successfully>\n",
      "=> loaded pre-trained model '/Users/felixkrones/python_projects/models/GMML/Finetune/CXR8/0.2.6_timm_imagenet_3D/seed_100/best_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:28<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating predictions\n",
      "diseases_to_test: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "index_to_test_dataset: [0, 1, 8, 9, 2, 10, 11, 13, 3, 4, 5, 12, 6, 7]\n",
      "Count: tensor([3279, 1069, 1815,  925, 4658, 1093,  435,   86, 6112, 1748, 1623, 1143,\n",
      "         555, 2665])\n",
      "Count from __get__: [3279 1069 1815  925 4658 1093  435   86 6112 1748 1623 1143  555 2665]\n",
      "AUC: [0.7737738390230443, 0.897192143836599, 0.759032889997258, 0.8503933604067365, 0.8324703542130827, 0.8940179627350373, 0.8296206910256569, 0.8805247372211534, 0.7059382854813884, 0.817135071509338, 0.7315291985266131, 0.7907199731346714, 0.7248861416825955, 0.860287985254401]\n",
      "Mean AUC: 0.8105\n",
      "Mean AUCs for all models\n",
      "['-- 0.2.4 --', 0.8071957142187917, 0.802746123424945, 0.8034253314139125, 0.8039466470815356, 0.8083479192809194, '-- 0.2.5 --', 0.807580741092012, 0.8112820245863095, 0.8093237017750533, 0.8125518689485431, 0.8074990015756611, '-- 0.2.6 --', 0.8064375263899958, 0.8113481594730828, 0.8126396013142985, 0.8119137209341251, 0.8105373310033982]\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "mean_auc = []\n",
    "for (model_name, model_path) in model_list:\n",
    "    if len(model_name) > 0:\n",
    "        print(f\"-------------- Model {model_name} from path: {model_path} --------------\")\n",
    "\n",
    "        # Load model\n",
    "        saved_model = os.path.join(model_path)\n",
    "        args.model_name = model_name\n",
    "\n",
    "        # Get predictions\n",
    "        y_test, p_test = test_classification(saved_model, data_loader_test, device, args)\n",
    "        print(\"Finished calculating predictions\")\n",
    "\n",
    "        # Filter predictions\n",
    "        y_test_filtered = y_test[:, index_to_test_dataset].type(torch.int64)\n",
    "        p_test_filtered = p_test[:, index_to_test_model]\n",
    "\n",
    "        # For padchest combine all atelectasis labels\n",
    "        if \"padchest\" in args.data_dir.lower():\n",
    "            index_atelectasis = [i for i, d in enumerate(diseases) if \"atelectasis\" in d.lower()]\n",
    "            y_test_filtered[:, diseases_to_test.index(\"Atelectasis\")] = torch.max(y_test[:, index_atelectasis], dim=1).values.type(torch.int64)\n",
    "\n",
    "        # Default metrics\n",
    "        all_results = metric_AUROC(y_test_filtered, p_test_filtered)\n",
    "        mean_over_all_classes = np.array([i for i in all_results if i > 0]).mean()\n",
    "\n",
    "        # Print results\n",
    "        print(f\"diseases_to_test: {diseases_to_test}\")\n",
    "        print(f\"index_to_test_dataset: {index_to_test_dataset}\")\n",
    "        try:\n",
    "            print(f\"Count from dataset: {sum(dataset_test.img_label[:, index_to_test_dataset])}\")\n",
    "            print(f\"Count from __get__: {sum(y_test_filtered)}\")\n",
    "        except:\n",
    "            print(\n",
    "                f\"Count: {sum(torch.from_numpy(np.array(dataset_test.img_label))[:, index_to_test_dataset])}\"\n",
    "            )\n",
    "            print(f\"Count from __get__: {sum(y_test_filtered.cpu().numpy())}\")\n",
    "        print(f\"AUC: {all_results}\")\n",
    "        print(f\"Mean AUC: {round(mean_over_all_classes, 4)}\")\n",
    "        mean_auc.append(mean_over_all_classes)\n",
    "\n",
    "        # Evaluate\n",
    "        eval_metrics = []\n",
    "        for decision_threshold in decision_thresholds:\n",
    "            eval_params[\"decision_threshold\"] = decision_threshold\n",
    "            eval_metrics.append(\n",
    "                plex_evaluate(\n",
    "                    preds=p_test_filtered.cpu().numpy(),\n",
    "                    target_labels=y_test_filtered.cpu().numpy(),\n",
    "                    eval_args=eval_params,\n",
    "                    meta_data=pd.read_csv(args.metadata_file)\n",
    "                    if args.metadata_file\n",
    "                    else None,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save metrics\n",
    "        metrics[model_path] = eval_metrics\n",
    "\n",
    "    else:\n",
    "        print(f\"-------------- Starting with experiment {model_path} --------------\")\n",
    "        mean_auc.append(f\"-- {model_path} --\")\n",
    "\n",
    "print(\"Mean AUCs for all models\")\n",
    "print(mean_auc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c928621",
   "metadata": {},
   "source": [
    "## 4. Print and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7940cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print\n",
    "for model_path, eval_metrics in metrics.items():\n",
    "    print(\n",
    "        f\"---------------------------------------- Model path: {model_path} ----------------------------------------\"\n",
    "    )\n",
    "    for eval_metric in eval_metrics:\n",
    "        print(\n",
    "            f\"--------------- Decision threshold: {eval_metric['decision_threshold']} ---------------\"\n",
    "        )\n",
    "        for key, value in eval_metric.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    print(\"--------------- Summary ---------------\")\n",
    "    print(f\"AUC: {eval_metrics[0]['auc']}\")\n",
    "    print(f\"Mean acc: {[i['mean_acc'] for i in eval_metrics]}\")\n",
    "    print(f\"Subset acc: {[i['subset_acc'] for i in eval_metrics]}\")\n",
    "    print(f\"Disparity: {[i['disparity'] for i in eval_metrics]}\")\n",
    "    print(f\"Underdiagnosis: {[i['underdiagnosis_mean'] for i in eval_metrics]}\")\n",
    "    print(f\"Calibration: {[i['calibration_error'] for i in eval_metrics]}\")\n",
    "    print(f\"Oracle AUC: {eval_metrics[0]['oracle_auc_mean']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "output_path = f\"./Outputs/Evaluation/{args.test_list.split('/')[-1].split('.')[0]}/{len(diseases_to_test)}_diseases/\"\n",
    "output_file = os.path.join(output_path, f\"{args.nc}D_{model_list[1][0]}_results.txt\")\n",
    "if not os.path.exists(\"/\".join(output_file.split(\"/\")[:-1])):\n",
    "    os.makedirs(output_path)\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6b5e0e1",
   "metadata": {},
   "source": [
    "## 5. Plot experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434621f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/Users/felixkrones/Library/CloudStorage/OneDrive-Personal/Dokumente/Studium_und_Schule/07_Oxford/PhD/08_Reliable/size_experiments.csv\"\n",
    "output_dir = \"/Users/felixkrones/Library/CloudStorage/OneDrive-Personal/Dokumente/Studium_und_Schule/07_Oxford/PhD/08_Reliable/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a28918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and standard deviation of the runs\n",
    "df['Mean'] = df[['Run1', 'Run2', 'Run3', 'Run4', 'Run5']].mean(axis=1)\n",
    "df['Std'] = df[['Run1', 'Run2', 'Run3', 'Run4', 'Run5']].std(axis=1)\n",
    "\n",
    "# list of unique experiments\n",
    "experiments = df['Experiment'].unique()\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# set font sizes\n",
    "title_font_size = 20\n",
    "axis_font_size = 18\n",
    "tick_font_size = 16\n",
    "legend_font_size = 16\n",
    "\n",
    "# iterate over experiments\n",
    "for experiment in experiments:\n",
    "    subset = df[df['Experiment'] == experiment]\n",
    "    # sort by size for plotting\n",
    "    subset = subset.sort_values(by='Size') \n",
    "    plt.plot(subset['Size'], subset['Mean'], 'o-', label=experiment) # 'o-' adds round markers\n",
    "    plt.fill_between(subset['Size'], subset['Mean'] - subset['Std'], subset['Mean'] + subset['Std'], alpha=0.1)\n",
    "\n",
    "plt.xlabel('Size', fontsize=axis_font_size)\n",
    "plt.ylabel('Mean of Runs', fontsize=axis_font_size)\n",
    "plt.xticks(fontsize=tick_font_size)\n",
    "plt.yticks(fontsize=tick_font_size)\n",
    "plt.legend(title='Experiments', fontsize=legend_font_size)\n",
    "plt.title('Mean of Runs with Standard Deviation for each Experiment', fontsize=title_font_size)\n",
    "\n",
    "plt.savefig(output_dir + 'experiment_size.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de24f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "ssl_benchmark_disease_diagnosis-TH-5Rskg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "118298914120c3bed14e6c153d818e4458def201929d094e31dfc514a45929f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
